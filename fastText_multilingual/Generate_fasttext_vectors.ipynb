{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sentence represenations aligned to English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First, let's define a few simple functions... (from https://github.com/Babylonpartners/fastText_multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fasttext import FastVector\n",
    "\n",
    "languages=['en','fr','it']\n",
    "language_extended=['english','french','italian']\n",
    "matrix_dir='alignment_matrices/'\n",
    "dic_dir='vectors/wiki.'\n",
    "rawdir='../data_clean/'\n",
    "feadir='features/'\n",
    "\n",
    "dictionary={}\n",
    "filenames={}\n",
    "outfiles={}\n",
    "\n",
    "# from https://stackoverflow.com/questions/21030391/how-to-normalize-array-numpy\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    \"\"\"Utility function to normalize the rows of a numpy array.\"\"\"\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "def make_training_matrices(source_dictionary, target_dictionary, bilingual_dictionary):\n",
    "    \"\"\"\n",
    "    Source and target dictionaries are the FastVector objects of\n",
    "    source/target languages. bilingual_dictionary is a list of \n",
    "    translation pair tuples [(source_word, target_word), ...].\n",
    "    \"\"\"\n",
    "    source_matrix = []\n",
    "    target_matrix = []\n",
    "\n",
    "    for (source, target) in bilingual_dictionary:\n",
    "        if source in source_dictionary and target in target_dictionary:\n",
    "            source_matrix.append(source_dictionary[source])\n",
    "            target_matrix.append(target_dictionary[target])\n",
    "\n",
    "    # return training matrices\n",
    "    return np.array(source_matrix), np.array(target_matrix)\n",
    "\n",
    "def learn_transformation(source_matrix, target_matrix, normalize_vectors=True):\n",
    "    \"\"\"\n",
    "    Source and target matrices are numpy arrays, shape\n",
    "    (dictionary_length, embedding_dimension). These contain paired\n",
    "    word vectors from the bilingual dictionary.\n",
    "    \"\"\"\n",
    "    # optionally normalize the training vectors\n",
    "    if normalize_vectors:\n",
    "        source_matrix = normalized(source_matrix)\n",
    "        target_matrix = normalized(target_matrix)\n",
    "\n",
    "    # perform the SVD\n",
    "    product = np.matmul(source_matrix.transpose(), target_matrix)\n",
    "    U, s, V = np.linalg.svd(product)\n",
    "\n",
    "    # return orthogonal transformation which aligns source language to the target\n",
    "    return np.matmul(U, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load filenames and word vectors. Non-english vectors are aligned to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filenames():\n",
    "    for lan,lext in zip(languages,language_extended):\n",
    "        #load clean data files\n",
    "        filenames[lan]=rawdir+lext+'.tsv'\n",
    "        #load output feature files\n",
    "        outfiles[lan]=feadir+lan+'.tsv'\n",
    "\n",
    "def load_dictionaries():\n",
    "    for lan in languages:\n",
    "        #load word vector dictionaries\n",
    "        dictionary[lan]= FastVector(vector_file=dic_dir+lan+'.vec')\n",
    "        #aligning all vectors to engglish\n",
    "        if lan !='en':\n",
    "            dictionary[lan].apply_transform(matrix_dir+lan+'.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we represent sentences with the algined vectos, and save the word representations in output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word vectors from vectors/wiki.en.vec\n",
      "reading word vectors from vectors/wiki.fr.vec\n",
      "reading word vectors from vectors/wiki.it.vec\n"
     ]
    }
   ],
   "source": [
    "#first load variables and dictionaries\n",
    "load_filenames()\n",
    "load_dictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every language, generate aligned vectors for clean sentences and write to file\n",
    "for lan in languages:\n",
    "    #open outfile for writing\n",
    "    fo=open(outfiles[lan],'w')\n",
    "    with open(filenames[lan]) as f:\n",
    "        #for every sentence in the clean filename\n",
    "        for line in f:\n",
    "            #isolate the text\n",
    "            row=line[:-1].split('\\t')\n",
    "            text=row[-2]\n",
    "            #split into words\n",
    "            words=text.split()\n",
    "            #populate vector with sum of word vectors\n",
    "            outvec=np.zeros(l)\n",
    "            count=0\n",
    "            for w in words:\n",
    "                try:\n",
    "                    outvec+=dictionary[lan][w]\n",
    "                    count=count+1\n",
    "                except:\n",
    "                    #there is no matching word in the dictionary\n",
    "                    pass\n",
    "            #divide by the total number of matching vetors\n",
    "            if count>0:\n",
    "                outvec /=count\n",
    "            outvec[outvec == np.nan] =0\n",
    "            outvec[outvec == np.inf] = 0\n",
    "            outvec[outvec == -np.inf] = 0\n",
    "            #build a comma-separated string for the sentence vectors\n",
    "            out=','.join([str(c) for c in outvec])\n",
    "            #rebuild output string\n",
    "            outstring='\\t'.join(row[:-2])+'\\t'+row[-1]+'\\t'+out+'\\n'\n",
    "            #writes to file\n",
    "            fo.write(outstring)\n",
    "    fo.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
